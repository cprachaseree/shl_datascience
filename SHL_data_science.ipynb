{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcDUFbiJaPQyjLgnh2vSAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cprachaseree/shl_datascience/blob/main/SHL_data_science.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data wrangling and library implementation"
      ],
      "metadata": {
        "id": "xFEsbz4-J5JI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are given a matrix A. Transform it into a new matrix B such that its i column has a mean i and variance i .\n",
        "Note: i equals 1 for the first column and increases sequentially.\n",
        "The input to the function editMatrix shall be a matrix X. Return the transformed matrix B.\n",
        "The test cases tab illustrates some examples."
      ],
      "metadata": {
        "id": "iGl3TDIGUCF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def editMatrix(A):\n",
        "    B = np.zeros(A.shape)\n",
        "    for j in range(A.shape[1]): # for each row\n",
        "        col_mean = A[:, j].mean()\n",
        "        col_std = A[:, j].std()\n",
        "        B[:, j] = (j + 1) * (j + 1) * (A[:, j] - col_mean) / col_std + (j + 1)\n",
        "    return B"
      ],
      "metadata": {
        "id": "AwPQ2GUUUFxv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "for i in range(1):\n",
        "    A = np.random.rand(4, 4)\n",
        "    B = editMatrix(A)\n",
        "    print(A)\n",
        "    print(B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_32-J94igfW7",
        "outputId": "2ff950bc-b5b0-4525-da5a-4c393bff2825"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5153917  0.42142499 0.42704058 0.81997677]\n",
            " [0.59408262 0.47548337 0.30943911 0.34900357]\n",
            " [0.70545768 0.89041964 0.74888284 0.08761036]\n",
            " [0.85918967 0.73615281 0.64558016 0.44039621]]\n",
            "[[ -0.18583528  -2.37821318  -2.48098384  28.11090824]\n",
            " [  0.42351075  -1.24818441  -8.57939149  -0.58438998]\n",
            " [  1.28594761   7.42558481  14.20864857 -16.51046841]\n",
            " [  2.47637692   4.20081277   8.85172677   4.98395015]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emma has to implement a classification algorithm for a 2-class problem. For each sample, her algorithm outputs the\n",
        "probability of the sample belonging to a particular class. She wants to evaluate the log-loss error of the predictions\n",
        "made by her algorithm."
      ],
      "metadata": {
        "id": "WcA1HVv6hL3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss_sklearn(y, y_pred):\n",
        "    from sklearn.metrics import log_loss\n",
        "    return log_loss(y, y_pred)\n",
        "\n",
        "def log_loss(y_true, y_pred):\n",
        "    loss = 0\n",
        "    for y_t, y_p in zip(y_true, y_pred):\n",
        "        loss += (y_t * np.log(y_p[1]) + (1-y_t) * np.log(y_p[0]))\n",
        "    return - loss / len(y_true)\n",
        "\n",
        "y_true = [0, 0, 1, 1]\n",
        "y_pred = [[.9, .1], [.8, .2], [.3, .7], [.01, .99]]\n",
        "res_log_loss_sklearn =  log_loss_sklearn(y_true, y_pred)\n",
        "print(res_log_loss_sklearn)\n",
        "res_log_loss =  log_loss(y_true, y_pred)\n",
        "print(res_log_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQbJvYCOhEsK",
        "outputId": "86750c99-2fca-433a-c78f-d442eb183f13"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1738073366910675\n",
            "0.1738073366910675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emma, a data scientist, wishes to build a spam classifier that can classify emails as spam or non-spam. When given an\n",
        "input email as a vector, the classifier returns the probability of an email being spam. Emma decides to use a threshold\n",
        "on probability values according to which the classifier will decide whether the email is spam. She makes a set of\n",
        "threshold values and calculates precision and recall for each, in order to gauge the performance at various thresholds\n",
        "\n",
        "mathbf{Precision=frac{t_p}\n",
        "{t_p+f_p}}\n",
        "\n",
        "mathbf{Recall=frac{t_p}\n",
        "{t_p+f_n}}\n"
      ],
      "metadata": {
        "id": "JQHcQaxOwK__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT LIBRARY PACKAGES NEEDED BY YOUR PROGRAM\n",
        "# SOME CLASSES WITHIN A PACKAGE MAY BE RESTRICTED\n",
        "# DEFINE ANY CLASS AND METHOD NEEDED\n",
        "# THIS FUNCTION IS REQUIRED\n",
        "#\n",
        "# Parameters: y: ndarray, shape (n_samples,1)\n",
        "# y_pred: ndarray, shape (n_samples,1)\n",
        "# Thres: list\n",
        "#\n",
        "# Returns: score: list\n",
        "#\n",
        "def computePrecisionRecall_1(y,y_pred,Thres):\n",
        "    # INSERT YOUR CODE HERE\n",
        "    import numpy as np\n",
        "    score = np.zeros((len(Thres), 2))\n",
        "    for i, thres in enumerate(Thres):\n",
        "        y_pred_bool = np.zeros(y_pred.shape)\n",
        "        y_pred_bool[y_pred >= thres] = 1\n",
        "        y_pred_bool[y_pred < thres] = 0\n",
        "        tp = np.sum((y == 1) & (y_pred_bool == 1))\n",
        "        fp = np.sum((y == 0) & (y_pred_bool == 1))\n",
        "        fn = np.sum((y == 1) & (y_pred_bool == 0))\n",
        "        score[i, 0] = tp / (tp + fp)\n",
        "        score[i, 1] = tp / (tp + fn)\n",
        "    return score\n",
        "\n",
        "def computePrecisionRecall_2(y,y_pred,Thres):\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    import numpy as np\n",
        "    score = np.zeros((len(Thres), 2))\n",
        "\n",
        "    for i, thres in enumerate(Thres):\n",
        "        y_pred_bool = np.zeros(y_pred.shape)\n",
        "        y_pred_bool[y_pred >= thres] = 1\n",
        "        y_pred_bool[y_pred < thres] = 0\n",
        "\n",
        "        score[i, 0] = precision_score(y, y_pred_bool)\n",
        "        score[i, 1] = recall_score(y, y_pred_bool)\n",
        "    return score\n",
        "\n",
        "y_true = np.array([0, 0, 1, 0, 1, 1])\n",
        "y_pred = np.array([0.1, 0.6, 0.8, 0.3, 0.9, 0.2])\n",
        "Thres = [0.3, 0.5, 0.8]\n",
        "score1 = computePrecisionRecall_1(y_true,y_pred,Thres)\n",
        "score2 = computePrecisionRecall_2(y_true,y_pred,Thres)\n",
        "print(score1)\n",
        "print(score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6t4puykwL67",
        "outputId": "120585b8-49d0-4bef-f844-24ecea1c794e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5        0.66666667]\n",
            " [0.66666667 0.66666667]\n",
            " [1.         0.66666667]]\n",
            "[[0.5        0.66666667]\n",
            " [0.66666667 0.66666667]\n",
            " [1.         0.66666667]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When building a predictive model, feature selection is an important step. You wish to find the best set of features in a\n",
        "data set. To know whether a feature is informative or not, you need to build a linear regression model using one\n",
        "feature at a time and compare its F-statistic with the rest of the features.\n",
        "Given a number k, identify the k best features in the data set provided to you.\n",
        "The inputs to the function fstatFeatures shall be the input matrix X, response matrix y, and an integer k. The function\n",
        "must return an array of booleans wherein the i element is 1 if the i feature is among the top k features. Otherwise\n",
        "the ith element is 0.\n",
        "The test cases tab illustrate some examples."
      ],
      "metadata": {
        "id": "dKI34z1oJsWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT LIBRARY PACKAGES NEEDED BY YOUR PROGRAM\n",
        "# SOME CLASSES WITHIN A PACKAGE MAY BE RESTRICTED\n",
        "# DEFINE ANY CLASS AND METHOD NEEDED\n",
        "# THIS FUNCTION IS REQUIRED\n",
        "#\n",
        "# Parameters: X: ndarray shape (n_samples,n_features)\n",
        "# y: ndarray shape(n_samples,1)\n",
        "# k: integer\n",
        "#\n",
        "# Returns: X_new: ndarray shape (n_samples,k)\n",
        "#\n",
        "def fstatFeatures(X,y,k):\n",
        "    #INSERT YOUR CODE HERE\n",
        "    from sklearn.feature_selection import f_regression\n",
        "    f_statistic, p = f_regression(X,y)\n",
        "    n = (-f_statistic).argsort()[:k]\n",
        "    res = np.array([0]*X.shape[1])\n",
        "    for i in n:\n",
        "        res[i] = 1\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "tzO__XKKJyCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML workflow implementation\n"
      ],
      "metadata": {
        "id": "jIPTRCIsKIzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your manager has asked you to build a prediction model using the company's marketing data. The data is a mix of\n",
        "numerical as well as categorical attributes. You only need to one-hot encode (N-1 dummy variables for N categories)\n",
        "the categorical attributes. You can use the numerical attributes as is.\n",
        "Given an input feature dataframe and a column matrix of true responses, your task is to build a prediction model using\n",
        "linear regression, after applying one-hot encoding on the categorical attributes. Calculate the Mean Squared Error\n",
        "(MSE) between the true responses and the predicted responses.\n",
        "The inputs to the function linearRegressionMSE shall be a dataframe X of features and a column matrix y of true\n",
        "responses. The function must return the Mean Squared Error (MSE).\n",
        "The test cases tab illustrates some examples"
      ],
      "metadata": {
        "id": "iJoNZp6vKOYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linearRegressionMSE(X,y):\n",
        "    import numpy as np\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    enc = OneHotEncoder()\n",
        "    ncols, nrows = X.shape\n",
        "    for col in X.columns:\n",
        "        if X[col].dtype == object:\n",
        "            unique, unique_inverse_indices = np.unique(X[col], return_inverse=True)\n",
        "            unique_inverse=unique_inverse.reshape(len(unique_inverse), 1)\n",
        "            bits=enc.fit_transform(unique_inverse).toarray()\n",
        "            bits=bits[:,range(0,bits.shape[1]-1)]\n",
        "\n",
        "            if(col=='c0'):\n",
        "                preds=bits\n",
        "            else:\n",
        "                preds=np.concatenate((preds,bits),axis=1)\n",
        "        else:\n",
        "            if(col=='c0'):\n",
        "                preds=X[col].values.reshape(nrows,1)\n",
        "            else:\n",
        "                preds=np.concatenate((preds,X[col].values.reshape(nrows, 1)),axis = 1)\n",
        "    LR = LinearRegression()\n",
        "    LR.fit(preds,y)\n",
        "    y_pred=LR.predict(preds)\n",
        "    ans=mean_squared_error(y,y_pred)\n",
        "    return ans\n",
        "\n"
      ],
      "metadata": {
        "id": "s8KkVImGKTEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# index\n",
        "a = np.array(['a', 'b', 'b', 'c', 'a'])\n",
        "u, indices = np.unique(a, return_index=True)\n",
        "u\n",
        "array(['a', 'b', 'c'], dtype='<U1')\n",
        "indices\n",
        "array([0, 1, 3])\n",
        "a[indices]\n",
        "array(['a', 'b', 'c'], dtype='<U1')\n",
        "\n",
        "# inverse\n",
        "a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
        "u, indices = np.unique(a, return_inverse=True)\n",
        "u\n",
        "array([1, 2, 3, 4, 6])\n",
        "indices\n",
        "array([0, 1, 4, 3, 1, 2, 1])\n",
        "u[indices]\n",
        "array([1, 2, 6, 4, 2, 3, 2])\n",
        "\n",
        "# counts\n",
        "a = np.array([1, 2, 6, 4, 2, 3, 2])\n",
        "values, counts = np.unique(a, return_counts=True)\n",
        "values\n",
        "array([1, 2, 3, 4, 6])\n",
        "counts\n",
        "array([1, 3, 1, 1, 1])\n",
        "np.repeat(values, counts)\n",
        "array([1, 2, 2, 2, 3, 4, 6])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "PBc_OJBuo8q9",
        "outputId": "f7a52a53-e0bf-491a-d264-a5cb1921eb8f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\na = np.array(['a', 'b', 'b', 'c', 'a'])\\nu, indices = np.unique(a, return_index=True)\\nu\\narray(['a', 'b', 'c'], dtype='<U1')\\nindices\\narray([0, 1, 3])\\na[indices]\\narray(['a', 'b', 'c'], dtype='<U1')\\n\\na = np.array([1, 2, 6, 4, 2, 3, 2])\\nu, indices = np.unique(a, return_inverse=True)\\nu\\narray([1, 2, 3, 4, 6])\\nindices\\narray([0, 1, 4, 3, 1, 2, 1])\\nu[indices]\\narray([1, 2, 6, 4, 2, 3, 2])\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Glen is a data science engineer at an online assessment company. The data from a particular test consists of various\n",
        "competency scores for candidates. His manager asks him to build a personality score prediction model based on the\n",
        "competency scores present in the input score data. He loads the input score data in a matrix and finds that some of\n",
        "the scores are missing. The missing scores are represented as NaNs. He decides to replace each NaN value with an\n",
        "average value of that feature. He then builds a model using linear regression to predict the values of personality\n",
        "scores. He evaluates his model by computing R-Squared statistic between actual and predicted personality scores.\n",
        "In this question, you must replicate Glen’s work.\n",
        "The input to the function linearRegressionWithMissingData shall be two matrices, X and y. X represents the input score\n",
        "data matrix and y represents the column matrix for personality scores. The function must return the computed R\u0002Squared statistic between actual and predicted personality scores.\n",
        "The test cases tab illustrates some examples."
      ],
      "metadata": {
        "id": "8eJybWABKTrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT LIBRARY PACKAGES NEEDED BY YOUR PROGRAM\n",
        "# SOME CLASSES WITHIN A PACKAGE MAY BE RESTRICTED\n",
        "# DEFINE ANY CLASS AND METHOD NEEDED\n",
        "# THIS FUNCTION IS REQUIRED\n",
        "#\n",
        "# Parameters: X: ndarray, shape (n_samples,n_features)\n",
        "# y: ndarray, shape (n_samples,1)\n",
        "#\n",
        "# Returns: score: float\n",
        "#\n",
        "def linearRegressionWithMissingData(X,y):\n",
        "    # INSERT YOUR CODE HERE\n",
        "    import numpy as np\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "\n",
        "    x_mean = np.nanmean(X, axis=0)\n",
        "\n",
        "    for i in range(X.shape[1]):\n",
        "        X[np.isnan(X[:, i]), i] = x_mean[i]\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model = model.fit(X, y)\n",
        "    score = model.score(X, y)\n",
        "    return score"
      ],
      "metadata": {
        "id": "9Zr732CvKacb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}